import os
import requests
import re
import base64
import cv2
import datetime
from datetime import datetime
from bs4 import BeautifulSoup
import fileinput
from opencc import OpenCC

# è·å–rtpç›®å½•ä¸‹çš„æ–‡ä»¶å
files = os.listdir('rtp')

files_name = []

# å»é™¤åç¼€åå¹¶ä¿å­˜è‡³provinces_isps
for file in files:
    name, extension = os.path.splitext(file)
    files_name.append(name)

# å¿½ç•¥ä¸ç¬¦åˆè¦æ±‚çš„æ–‡ä»¶å
provinces_isps = [name for name in files_name if name.count('_') == 1]

# æ‰“å°ç»“æœ
print(f"æœ¬æ¬¡æŸ¥è¯¢ï¼š{provinces_isps}çš„ç»„æ’­èŠ‚ç›®")

keywords = []

for province_isp in provinces_isps:
    # è¯»å–æ–‡ä»¶å¹¶åˆ é™¤ç©ºç™½è¡Œ
    try:
        with open(f'rtp/{province_isp}.txt', 'r', encoding='utf-8') as file:
            lines = file.readlines()
            lines = [line.strip() for line in lines if line.strip()]
        # è·å–ç¬¬ä¸€è¡Œä¸­ä»¥åŒ…å« "rtp://" çš„å€¼ä½œä¸º mcast
        if lines:
            first_line = lines[0]
            if "rtp://" in first_line:
                mcast = first_line.split("rtp://")[1].split(" ")[0]
                keywords.append(province_isp + "_" + mcast)
    except FileNotFoundError:
        print(f"æ–‡ä»¶ '{province_isp}.txt' ä¸å­˜åœ¨. è·³è¿‡æ­¤æ–‡ä»¶.")

for keyword in keywords:
    province, isp, mcast = keyword.split("_")
    # æ ¹æ®ä¸åŒçš„ isp è®¾ç½®ä¸åŒçš„ org å€¼
    if province == "åŒ—äº¬" and isp == "è”é€š":
        org = "China Unicom Beijing Province Network"
    elif isp == "è”é€š":
        org = "CHINA UNICOM China169 Backbone"
    elif isp == "ç”µä¿¡":
        org = "Chinanet"
    elif isp == "ç§»åŠ¨":
        org = "China Mobile communications corporation"

    current_time = datetime.now()
    timeout_cnt = 0
    result_urls = set() 
    while len(result_urls) == 0 and timeout_cnt <= 5:
        try:
            search_url = 'https://fofa.info/result?qbase64='
            search_txt = f'\"Rozhuk\" && country=\"CN\" && region=\"{province}\"'
            bytes_string = search_txt.encode('utf-8')
            search_txt = base64.b64encode(bytes_string).decode('utf-8')
            search_url += search_txt
            print(f"{current_time} æŸ¥è¯¢è¿è¥å•† : {province}{isp} ï¼ŒæŸ¥è¯¢ç½‘å€ : {search_url}")
            response = requests.get(search_url, timeout=30)
            response.raise_for_status()
            html_content = response.text
            html_soup = BeautifulSoup(html_content, "html.parser")
            pattern = r"http://\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d+"
            urls_all = re.findall(pattern, html_content)
            result_urls = set(urls_all)
            print(f"{current_time} result_urls:{result_urls}")

            valid_ips = []

            # éå†æ‰€æœ‰è§†é¢‘é“¾æ¥
            for url in result_urls:
                video_url = url + "/rtp/" + mcast

                # ç”¨OpenCVè¯»å–è§†é¢‘
                cap = cv2.VideoCapture(video_url)

                # æ£€æŸ¥è§†é¢‘æ˜¯å¦æˆåŠŸæ‰“å¼€
                if not cap.isOpened():
                    print(f"{current_time} {video_url} æ— æ•ˆ")
                    continue  # Skip to the next URL

                # è¯»å–è§†é¢‘çš„å®½åº¦å’Œé«˜åº¦
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                print(f"{current_time} {video_url} çš„åˆ†è¾¨ç‡ä¸º {width}x{height}")

                if width > 0 and height > 0:
                    valid_ips.append(url)
                cap.release()

            if valid_ips:
                rtp_filename = f'rtp/{province}_{isp}.txt'
                with open(rtp_filename, 'r', encoding='utf-8') as file:
                    data = file.read()
                txt_filename = f'{province}{isp}.txt'
                with open(txt_filename, 'w') as new_file:
                    for url in valid_ips:
                        new_data = data.replace("rtp://", f"{url}/rtp/")
                        new_file.write(new_data)

                print(f'å·²ç”Ÿæˆæ’­æ”¾åˆ—è¡¨ï¼Œä¿å­˜è‡³{txt_filename}')
            else:
                print(f"æœªæ‰¾åˆ°åˆé€‚çš„ IP åœ°å€ã€‚")

        except (requests.Timeout, requests.RequestException) as e:
            timeout_cnt += 1
            print(f"{current_time} [{province}]æœç´¢è¯·æ±‚å‘ç”Ÿè¶…æ—¶ï¼Œå¼‚å¸¸æ¬¡æ•°ï¼š{timeout_cnt}")
            if timeout_cnt <= 5:
                continue
            else:
                print(f"{current_time} æœç´¢IPTVé¢‘é“æº[]ï¼Œè¶…æ—¶æ¬¡æ•°è¿‡å¤šï¼š{timeout_cnt} æ¬¡ï¼Œåœæ­¢å¤„ç†")
print('èŠ‚ç›®è¡¨åˆ¶ä½œå®Œæˆï¼ æ–‡ä»¶è¾“å‡ºåœ¨å½“å‰æ–‡ä»¶å¤¹ï¼')

# åˆå¹¶è‡ªå®šä¹‰é¢‘é“æ–‡ä»¶
file_contents = []
grouped_contents = {
    'ğŸ’šå¤®è§†é¢‘é“&çˆ¬è™«,#genre#': [],
    'ğŸ’šå«è§†é¢‘é“&çˆ¬è™«,#genre#': [],
    'ğŸ’šæ•°å­—é¢‘é“&çˆ¬è™«,#genre#': [],
    'ğŸ’šçœçº§é¢‘é“&çˆ¬è™«,#genre#': [],
    'ğŸ’šå‡¤å‡°CHC&çˆ¬è™«,#genre#': [],
}

file_paths = ["c.txt", "c1.txt", "c2.txt", "e.txt", "DD.txt", "df.txt", "df1.txt", "f.txt", "f1.txt"]  # æ›¿æ¢ä¸ºå®é™…çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
for file_path in file_paths:
    if os.path.exists(file_path):
        with open(file_path, 'r', encoding="utf-8") as file:
            content = file.readlines()
            # å°†å†…å®¹æŒ‰ç»„å­˜å…¥å­—å…¸
            for line in content:
                for key in grouped_contents.keys():
                    if key in line:
                        grouped_contents[key].append(line)
                        break  # æ‰¾åˆ°å¯¹åº”ç»„ååœæ­¢

# å°†å†…å®¹æŒ‰éœ€è¦çš„é¡ºåºå†™å…¥åˆå¹¶åçš„æ–‡ä»¶
with open("GAT.txt", "w", encoding="utf-8") as output:
    # æŒ‰é¡ºåºå†™å…¥ä¸åŒçš„åˆ†ç»„
    for group in ['ğŸ’šå¤®è§†é¢‘é“&çˆ¬è™«,#genre#', 'ğŸ’šå«è§†é¢‘é“&çˆ¬è™«,#genre#', 'ğŸ’šæ•°å­—é¢‘é“&çˆ¬è™«,#genre#', 'ğŸ’šçœçº§é¢‘é“&çˆ¬è™«,#genre#', 'ğŸ’šå‡¤å‡°CHC&çˆ¬è™«,#genre#']:
        if group in grouped_contents:
            output.write(''.join(grouped_contents[group]))

# è¯»å–ä¸´æ—¶æ–‡ä»¶ï¼Œå¹¶ç”Ÿæˆç»“æœæ–‡ä»¶
with open("GAT.txt", 'r', encoding="utf-8") as file:
    content = file.read()

# å†™å…¥åˆå¹¶åçš„æ–‡ä»¶
with open("iptv_list.txt", "w", encoding="utf-8") as output:
    output.write(content)

for line in fileinput.input("iptv_list.txt", inplace=True):
    line = line.replace("008å¹¿", "å¹¿")
    line = line.replace("å®¶åº­ç”µå½±", "å®¶åº­å½±é™¢")    
    line = line.replace("CHC", "CHC")  
    print(line, end="")

with open('iptv_list.txt', 'r', encoding="utf-8") as file:
    lines = file.readlines()

# ä½¿ç”¨åˆ—è¡¨æ¥å­˜å‚¨å”¯ä¸€çš„è¡Œçš„é¡ºåº 
unique_lines = [] 
seen_lines = set() 

# éå†æ¯ä¸€è¡Œï¼Œå¦‚æœæ˜¯æ–°çš„å°±åŠ å…¥unique_lines 
for line in lines:
    if line not in seen_lines:
        unique_lines.append(line)
        seen_lines.add(line)

# å°†å”¯ä¸€çš„è¡Œå†™å…¥æ–°çš„æ–‡æ¡£ 
with open('iptv_list.txt', 'w', encoding="utf-8") as file:
    file.writelines(unique_lines)

# ç®€ä½“è½¬ç¹ä½“
converter = OpenCC('t2s.json')  # ç¹è½¬ç®€
with open('iptv_list.txt', 'r', encoding='utf-8') as file:
    traditional_text = file.read()

# è¿›è¡Œç¹ä½“å­—è½¬ç®€ä½“å­—çš„è½¬æ¢
simplified_text = converter.convert(traditional_text)

# å°†è½¬æ¢åçš„ç®€ä½“å­—å†™å…¥txtæ–‡ä»¶
with open('iptv_list.txt', 'w', encoding='utf-8') as file:
    file.write(simplified_text)

# TXTè½¬M3U
def txt_to_m3u(input_file, output_file):
    # è¯»å–txtæ–‡ä»¶å†…å®¹
    with open(input_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    # æ‰“å¼€m3uæ–‡ä»¶å¹¶å†™å…¥å†…å®¹
    now = datetime.utcnow() + datetime.timedelta(hours=8)
    current_time = now.strftime("%m-%d %H:%M")
    with open(output_file, 'w', encoding='utf-8') as f:  
        f.write('#EXTM3U x-tvg-url="https://live.fanmingming.com/e.xml" catchup="append" catchup-source="?playseek=${(b)yyyyMMddHHmmss}-${(e)yyyyMMddHHmmss}"\n')
        f.write(f'#EXTINF:-1 group-title="ğŸ’šæ›´æ–°æ—¶é—´{current_time}",æ²³å—å«è§†\n')    
        f.write(f'http://61.163.181.78:9901/tsfile/live/1034_1.m3u8?key=txiptv&playlive=1&authid=0\n')    
        # åˆå§‹åŒ–genreå˜é‡
        genre = ''
        # éå†txtæ–‡ä»¶å†…å®¹
        for line in lines:
            line = line.strip()
            if "," in line:  # é˜²æ­¢æ–‡ä»¶é‡Œé¢ç¼ºå¤±","å·æŠ¥é”™
                channel_name, channel_url = line.split(',', 1)
                if channel_url == '#genre#':
                    genre = channel_name
                    print(genre)
                else:
                    # å°†é¢‘é“ä¿¡æ¯å†™å…¥m3uæ–‡ä»¶
                    f.write(f'#EXTINF:-1 tvg-id="{channel_name}" tvg-name="{channel_name}" tvg-logo="https://live.fanmingming.com/tv/{channel_name}.png" group-title="{genre}",{channel_name}\n')
                    f.write(f'{channel_url}\n')

# å°†txtæ–‡ä»¶è½¬æ¢ä¸ºm3uæ–‡ä»¶
txt_to_m3u('iptv_list.txt', 'iptv_list.m3u')

# ä»»åŠ¡ç»“æŸï¼Œåˆ é™¤ä¸å¿…è¦çš„è¿‡ç¨‹æ–‡ä»¶
files_to_remove = ["åŒ—äº¬è”é€š.txt", "ä¸Šæµ·ç”µä¿¡.txt", "æ±Ÿè‹ç”µä¿¡.txt", "å¤©æ´¥è”é€š.txt", "æ¹–åŒ—ç”µä¿¡.txt", "æ¹–å—ç”µä¿¡.txt", "å¹¿ä¸œç”µä¿¡.txt", "é™•è¥¿ç”µä¿¡.txt", "å››å·ç”µä¿¡.txt", "æ²³å—ç”µä¿¡.txt", "æ²³å—è”é€š.txt", "GAT.txt", "DD.txt", "TW.txt", "a.txt", "b.txt", "b2.txt", "HK.txt", "c.txt", "c1.txt", "c2.txt", "e.txt", "f.txt", "f1.txt", "df.txt", "df1.txt", "TT.txt", "zhibo.txt"]

for file in files_to_remove:
    if os.path.exists(file):
        os.remove(file)
    else:  # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™æç¤ºå¼‚å¸¸å¹¶æ‰“å°æç¤ºä¿¡æ¯
        print(f"æ–‡ä»¶ {file} ä¸å­˜åœ¨ï¼Œè·³è¿‡åˆ é™¤ã€‚")

print("ä»»åŠ¡è¿è¡Œå®Œæ¯•ï¼Œåˆ†ç±»é¢‘é“åˆ—è¡¨å¯æŸ¥çœ‹æ–‡ä»¶å¤¹å†…iptv_list.txtæ–‡ä»¶ï¼")
